{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Job Role     Experience Qualifications Salary Range    location  \\\n",
      "0         1  5 to 15 Years         M.Tech    $59K-$99K     Douglas   \n",
      "1         2  2 to 12 Years            BCA   $56K-$116K    Ashgabat   \n",
      "2         3  0 to 12 Years            PhD   $61K-$104K       Macao   \n",
      "3         4  4 to 11 Years            PhD    $65K-$91K  Porto-Novo   \n",
      "4         5  1 to 12 Years            MBA    $64K-$87K    Santiago   \n",
      "\n",
      "            Country  Work Type  Company Size Job Posting Date Preference  ...  \\\n",
      "0       Isle of Man     Intern         26801       2022-04-24     Female  ...   \n",
      "1      Turkmenistan     Intern        100340       2022-12-19     Female  ...   \n",
      "2  Macao SAR, China  Temporary         84525       2022-09-14       Male  ...   \n",
      "3             Benin  Full-Time        129896       2023-02-25     Female  ...   \n",
      "4             Chile     Intern         53944       2022-10-11     Female  ...   \n",
      "\n",
      "                 Contact                     Job Title  \\\n",
      "0   001-381-930-7517x737  Digital Marketing Specialist   \n",
      "1           461-509-4216                 Web Developer   \n",
      "2             9687619505            Operations Manager   \n",
      "3  +1-820-643-5431x47576              Network Engineer   \n",
      "4      343.975.4702x9340                 Event Manager   \n",
      "\n",
      "                        Role    Job Portal  \\\n",
      "0       Social Media Manager      Snagajob   \n",
      "1     Frontend Web Developer      Idealist   \n",
      "2    Quality Control Manager  Jobs2Careers   \n",
      "3  Wireless Network Engineer      FlexJobs   \n",
      "4         Conference Manager  Jobs2Careers   \n",
      "\n",
      "                                     Job Description  \\\n",
      "0  Social Media Managers oversee an organizations...   \n",
      "1  Frontend Web Developers design and implement u...   \n",
      "2  Quality Control Managers establish and enforce...   \n",
      "3  Wireless Network Engineers design, implement, ...   \n",
      "4  A Conference Manager coordinates and manages c...   \n",
      "\n",
      "                                            Benefits  \\\n",
      "0  {'Flexible Spending Accounts (FSAs), Relocatio...   \n",
      "1  {'Health Insurance, Retirement Plans, Paid Tim...   \n",
      "2  {'Legal Assistance, Bonuses and Incentive Prog...   \n",
      "3  {'Transportation Benefits, Professional Develo...   \n",
      "4  {'Flexible Spending Accounts (FSAs), Relocatio...   \n",
      "\n",
      "                                              skills  \\\n",
      "0  Social media platforms (e.g., Facebook, Twitte...   \n",
      "1  HTML, CSS, JavaScript Frontend frameworks (e.g...   \n",
      "2  Quality control processes and methodologies St...   \n",
      "3  Wireless network design and architecture Wi-Fi...   \n",
      "4  Event planning Conference logistics Budget man...   \n",
      "\n",
      "                                    Responsibilities  \\\n",
      "0  Manage and grow social media accounts, create ...   \n",
      "1  Design and code user interfaces for websites, ...   \n",
      "2  Establish and enforce quality control standard...   \n",
      "3  Design, configure, and optimize wireless netwo...   \n",
      "4  Specialize in conference and convention planni...   \n",
      "\n",
      "                            Company  \\\n",
      "0                 Icahn Enterprises   \n",
      "1      PNC Financial Services Group   \n",
      "2  United Services Automobile Assn.   \n",
      "3                              Hess   \n",
      "4                      Cairn Energy   \n",
      "\n",
      "                                     Company Profile  \n",
      "0  {\"Sector\":\"Diversified\",\"Industry\":\"Diversifie...  \n",
      "1  {\"Sector\":\"Financial Services\",\"Industry\":\"Com...  \n",
      "2  {\"Sector\":\"Insurance\",\"Industry\":\"Insurance: P...  \n",
      "3  {\"Sector\":\"Energy\",\"Industry\":\"Mining, Crude-O...  \n",
      "4  {\"Sector\":\"Energy\",\"Industry\":\"Energy - Oil & ...  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Job Role          999 non-null    int64 \n",
      " 1   Experience        999 non-null    object\n",
      " 2   Qualifications    999 non-null    object\n",
      " 3   Salary Range      999 non-null    object\n",
      " 4   location          999 non-null    object\n",
      " 5   Country           999 non-null    object\n",
      " 6   Work Type         999 non-null    object\n",
      " 7   Company Size      999 non-null    int64 \n",
      " 8   Job Posting Date  999 non-null    object\n",
      " 9   Preference        999 non-null    object\n",
      " 10  Contact Person    999 non-null    object\n",
      " 11  Contact           999 non-null    object\n",
      " 12  Job Title         999 non-null    object\n",
      " 13  Role              999 non-null    object\n",
      " 14  Job Portal        999 non-null    object\n",
      " 15  Job Description   999 non-null    object\n",
      " 16  Benefits          999 non-null    object\n",
      " 17  skills            999 non-null    object\n",
      " 18  Responsibilities  999 non-null    object\n",
      " 19  Company           999 non-null    object\n",
      " 20  Company Profile   997 non-null    object\n",
      "dtypes: int64(2), object(19)\n",
      "memory usage: 164.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Job_ML_Filtered.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display dataset structure\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_avg_salary(salary):\n",
    "    try:\n",
    "        salary = salary.replace('$', '').replace('K', '').split('-')\n",
    "        # Convert to integer and calculate average\n",
    "        return (int(salary[0]) + int(salary[1])) / 2\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the dataset\n",
    "data['Salary Range'] = data['Salary Range'].apply(extract_avg_salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode categorical variables:\n",
    "label_encoders = {}\n",
    "for col in ['Qualifications', 'Work Type']:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize skills using TF-IDF:\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "skills_tfidf = tfidf.fit_transform(data['skills'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Combine Features and Define the Target\n",
    "# Combine numeric and text features\n",
    "X = np.hstack([\n",
    "    data[['Experience', 'Qualifications', 'Salary Range', 'Work Type']].fillna(0).values,\n",
    "    skills_tfidf.toarray()\n",
    "])\n",
    "\n",
    "# Encode the target variable (Role)\n",
    "label_encoder_role = LabelEncoder()\n",
    "y = label_encoder_role.fit_transform(data['Role'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '5 to 13 Years'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#6. Train a Machine Learning Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Train Random Forest Classifier\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cheta\\Python\\venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cheta\\Python\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32mc:\\Users\\cheta\\Python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\cheta\\Python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\cheta\\Python\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cheta\\Python\\venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '5 to 13 Years'"
     ]
    }
   ],
   "source": [
    "#6. Train a Machine Learning Model\n",
    "# Train Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       1.00      1.00      1.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       1.00      1.00      1.00         1\n",
      "          22       1.00      1.00      1.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       1.00      1.00      1.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       0.00      0.00      0.00         0\n",
      "          33       0.00      0.00      0.00         0\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         0\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       1.00      1.00      1.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       1.00      1.00      1.00         3\n",
      "          47       1.00      1.00      1.00         1\n",
      "          48       1.00      1.00      1.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       1.00      1.00      1.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         0\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         0\n",
      "          58       1.00      1.00      1.00         1\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         0\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       1.00      1.00      1.00         1\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       0.00      0.00      0.00         0\n",
      "          68       1.00      1.00      1.00         1\n",
      "          69       0.00      0.00      0.00         0\n",
      "          70       1.00      1.00      1.00         2\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00         0\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         2\n",
      "          77       1.00      1.00      1.00         1\n",
      "          78       1.00      1.00      1.00         1\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         0\n",
      "          82       1.00      1.00      1.00         1\n",
      "          83       0.00      0.00      0.00         0\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       1.00      1.00      1.00         4\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       1.00      1.00      1.00         1\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       1.00      1.00      1.00         1\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       1.00      1.00      1.00         1\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       1.00      1.00      1.00         1\n",
      "          98       0.50      1.00      0.67         1\n",
      "          99       1.00      1.00      1.00         1\n",
      "         100       0.00      0.00      0.00         0\n",
      "         101       1.00      1.00      1.00         1\n",
      "         102       1.00      1.00      1.00         1\n",
      "         103       1.00      1.00      1.00         1\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.67      1.00      0.80         2\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         0\n",
      "         110       0.00      0.00      0.00         0\n",
      "         111       0.00      0.00      0.00         0\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       1.00      1.00      1.00         1\n",
      "         116       1.00      1.00      1.00         2\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       0.00      0.00      0.00         0\n",
      "         119       1.00      1.00      1.00         1\n",
      "         120       1.00      1.00      1.00         2\n",
      "         121       0.00      0.00      0.00         0\n",
      "         122       1.00      1.00      1.00         1\n",
      "         123       0.00      0.00      0.00         0\n",
      "         124       1.00      1.00      1.00         1\n",
      "         125       1.00      1.00      1.00         2\n",
      "         126       1.00      1.00      1.00         1\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       1.00      1.00      1.00         1\n",
      "         129       1.00      1.00      1.00         1\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       1.00      1.00      1.00         2\n",
      "         132       1.00      1.00      1.00         1\n",
      "         133       1.00      1.00      1.00         2\n",
      "         134       1.00      1.00      1.00         4\n",
      "         135       0.00      0.00      0.00         0\n",
      "         136       0.00      0.00      0.00         0\n",
      "         137       0.00      0.00      0.00         0\n",
      "         138       1.00      1.00      1.00         2\n",
      "         139       1.00      1.00      1.00         1\n",
      "         140       0.00      0.00      0.00         0\n",
      "         141       0.00      0.00      0.00         0\n",
      "         142       0.00      0.00      0.00         0\n",
      "         143       0.00      0.00      0.00         0\n",
      "         144       1.00      1.00      1.00         1\n",
      "         145       0.00      0.00      0.00         0\n",
      "         146       0.00      0.00      0.00         0\n",
      "         147       0.00      0.00      0.00         0\n",
      "         148       0.50      1.00      0.67         1\n",
      "         149       1.00      1.00      1.00         1\n",
      "         150       0.00      0.00      0.00         0\n",
      "         151       0.00      0.00      0.00         0\n",
      "         152       0.00      0.00      0.00         0\n",
      "         153       0.00      0.00      0.00         0\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       1.00      1.00      1.00         2\n",
      "         156       0.00      0.00      0.00         0\n",
      "         157       0.00      0.00      0.00         0\n",
      "         158       0.00      0.00      0.00         0\n",
      "         159       0.00      0.00      0.00         0\n",
      "         160       1.00      1.00      1.00         4\n",
      "         161       1.00      1.00      1.00         2\n",
      "         162       0.00      0.00      0.00         0\n",
      "         163       1.00      1.00      1.00         1\n",
      "         164       0.00      0.00      0.00         0\n",
      "         165       0.00      0.00      0.00         0\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       0.00      0.00      0.00         0\n",
      "         168       0.00      0.00      0.00         0\n",
      "         169       0.00      0.00      0.00         0\n",
      "         170       0.00      0.00      0.00         0\n",
      "         171       0.00      0.00      0.00         0\n",
      "         172       1.00      1.00      1.00         2\n",
      "         173       1.00      1.00      1.00         1\n",
      "         174       0.00      0.00      0.00         0\n",
      "         175       0.00      0.00      0.00         0\n",
      "         176       0.00      0.00      0.00         0\n",
      "         177       0.00      0.00      0.00         0\n",
      "         178       1.00      1.00      1.00         1\n",
      "         179       1.00      1.00      1.00         1\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       1.00      1.00      1.00         1\n",
      "         182       0.00      0.00      0.00         0\n",
      "         183       0.00      0.00      0.00         0\n",
      "         184       1.00      1.00      1.00         1\n",
      "         185       0.00      0.00      0.00         0\n",
      "         186       0.00      0.00      0.00         1\n",
      "         187       0.00      0.00      0.00         0\n",
      "         188       0.00      0.00      0.00         1\n",
      "         189       1.00      1.00      1.00         1\n",
      "         190       0.00      0.00      0.00         1\n",
      "         191       1.00      1.00      1.00         1\n",
      "         192       0.00      0.00      0.00         0\n",
      "         193       0.00      0.00      0.00         0\n",
      "         194       0.00      0.00      0.00         0\n",
      "         195       0.00      0.00      0.00         0\n",
      "         196       1.00      1.00      1.00         1\n",
      "         197       1.00      1.00      1.00         2\n",
      "         198       0.00      0.00      0.00         0\n",
      "         199       0.00      0.00      0.00         0\n",
      "         200       0.00      0.00      0.00         0\n",
      "         201       1.00      1.00      1.00         1\n",
      "         202       1.00      1.00      1.00         1\n",
      "         203       0.00      0.00      0.00         0\n",
      "         204       0.00      0.00      0.00         0\n",
      "         205       0.00      0.00      0.00         0\n",
      "         206       0.00      0.00      0.00         0\n",
      "         207       0.00      0.00      0.00         0\n",
      "         208       0.00      0.00      0.00         0\n",
      "         209       0.00      0.00      0.00         0\n",
      "         210       0.00      0.00      0.00         0\n",
      "         211       0.00      0.00      0.00         0\n",
      "         212       0.00      0.00      0.00         0\n",
      "         213       0.00      0.00      0.00         0\n",
      "         214       0.00      0.00      0.00         0\n",
      "         215       0.00      0.00      0.00         0\n",
      "         216       0.00      0.00      0.00         0\n",
      "         217       1.00      1.00      1.00         1\n",
      "         218       1.00      1.00      1.00         1\n",
      "         219       0.50      1.00      0.67         1\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.50      1.00      0.67         1\n",
      "         222       0.00      0.00      0.00         0\n",
      "         223       0.75      1.00      0.86         3\n",
      "         224       1.00      1.00      1.00         1\n",
      "         225       0.00      0.00      0.00         0\n",
      "         226       0.00      0.00      0.00         0\n",
      "         227       0.00      0.00      0.00         0\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         0\n",
      "         230       0.00      0.00      0.00         0\n",
      "         231       1.00      1.00      1.00         4\n",
      "         232       0.00      0.00      0.00         0\n",
      "         233       1.00      1.00      1.00         2\n",
      "         234       0.00      0.00      0.00         0\n",
      "         235       0.00      0.00      0.00         0\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         0\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         0\n",
      "         240       1.00      1.00      1.00         1\n",
      "         241       0.00      0.00      0.00         0\n",
      "         242       0.00      0.00      0.00         0\n",
      "         243       1.00      1.00      1.00         2\n",
      "         244       1.00      1.00      1.00         1\n",
      "         245       0.00      0.00      0.00         0\n",
      "         246       0.00      0.00      0.00         0\n",
      "         247       0.00      0.00      0.00         0\n",
      "         248       1.00      1.00      1.00         1\n",
      "         249       0.00      0.00      0.00         0\n",
      "         250       0.00      0.00      0.00         0\n",
      "         251       1.00      1.00      1.00         1\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         0\n",
      "         254       0.00      0.00      0.00         0\n",
      "         255       0.00      0.00      0.00         0\n",
      "         256       1.00      1.00      1.00         1\n",
      "         257       0.00      0.00      0.00         0\n",
      "         258       1.00      1.00      1.00         1\n",
      "         259       0.00      0.00      0.00         0\n",
      "         260       0.00      0.00      0.00         0\n",
      "         261       0.00      0.00      0.00         0\n",
      "         262       1.00      1.00      1.00         2\n",
      "         263       0.00      0.00      0.00         0\n",
      "         264       0.00      0.00      0.00         0\n",
      "         265       1.00      1.00      1.00         1\n",
      "         266       0.00      0.00      0.00         0\n",
      "         267       0.00      0.00      0.00         0\n",
      "         268       0.00      0.00      0.00         0\n",
      "         269       0.00      0.00      0.00         0\n",
      "         270       0.00      0.00      0.00         0\n",
      "         271       0.00      0.00      0.00         0\n",
      "         272       0.00      0.00      0.00         0\n",
      "         273       0.00      0.00      0.00         0\n",
      "         274       1.00      1.00      1.00         1\n",
      "         275       1.00      1.00      1.00         1\n",
      "         276       1.00      1.00      1.00         1\n",
      "         277       1.00      1.00      1.00         1\n",
      "         278       1.00      1.00      1.00         2\n",
      "         279       0.00      0.00      0.00         0\n",
      "         280       1.00      1.00      1.00         1\n",
      "         281       0.00      0.00      0.00         0\n",
      "         282       1.00      1.00      1.00         3\n",
      "         283       0.00      0.00      0.00         0\n",
      "         284       1.00      1.00      1.00         1\n",
      "         285       0.00      0.00      0.00         0\n",
      "         286       1.00      1.00      1.00         1\n",
      "         287       0.67      1.00      0.80         2\n",
      "         288       1.00      1.00      1.00         2\n",
      "         289       0.00      0.00      0.00         0\n",
      "         290       1.00      1.00      1.00         1\n",
      "         291       0.00      0.00      0.00         0\n",
      "         292       0.67      1.00      0.80         2\n",
      "         293       1.00      1.00      1.00         1\n",
      "         294       1.00      1.00      1.00         2\n",
      "         295       0.00      0.00      0.00         0\n",
      "         296       0.00      0.00      0.00         1\n",
      "         297       0.00      0.00      0.00         0\n",
      "         298       0.00      0.00      0.00         0\n",
      "         299       0.00      0.00      0.00         0\n",
      "         300       1.00      1.00      1.00         1\n",
      "         301       1.00      1.00      1.00         1\n",
      "         302       0.00      0.00      0.00         0\n",
      "         303       1.00      1.00      1.00         3\n",
      "         304       0.00      0.00      0.00         0\n",
      "         305       1.00      1.00      1.00         2\n",
      "         306       1.00      1.00      1.00         1\n",
      "         307       0.00      0.00      0.00         2\n",
      "         308       0.00      0.00      0.00         0\n",
      "         309       1.00      1.00      1.00         1\n",
      "         310       0.00      0.00      0.00         0\n",
      "         311       0.00      0.00      0.00         0\n",
      "         312       0.00      0.00      0.00         0\n",
      "         313       0.00      0.00      0.00         0\n",
      "         314       0.00      0.00      0.00         0\n",
      "         315       0.00      0.00      0.00         0\n",
      "         316       0.00      0.00      0.00         0\n",
      "         317       0.00      0.00      0.00         0\n",
      "         318       0.00      0.00      0.00         0\n",
      "         319       0.00      0.00      0.00         0\n",
      "         320       0.00      0.00      0.00         0\n",
      "         321       0.50      1.00      0.67         1\n",
      "         322       1.00      1.00      1.00         1\n",
      "         323       0.00      0.00      0.00         1\n",
      "         324       1.00      1.00      1.00         1\n",
      "         325       1.00      1.00      1.00         3\n",
      "         326       1.00      1.00      1.00         2\n",
      "         327       0.00      0.00      0.00         0\n",
      "         328       1.00      1.00      1.00         1\n",
      "         329       0.00      0.00      0.00         0\n",
      "         330       0.00      0.00      0.00         0\n",
      "         331       0.00      0.00      0.00         0\n",
      "         332       1.00      1.00      1.00         1\n",
      "         333       1.00      1.00      1.00         1\n",
      "         334       0.00      0.00      0.00         0\n",
      "         335       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.37      0.38      0.37       200\n",
      "weighted avg       0.87      0.90      0.88       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ds39\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#7. Evaluate the Model\n",
    "# Predict on the test set\n",
    "# Generate classification report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "labels = np.unique(y)  # All possible classes in the target variable\n",
    "print(classification_report(y_test, y_pred, labels=labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Save Preprocessing and Model (Optional)\n",
    "import pickle\n",
    "\n",
    "# Save the trained model and encoders\n",
    "pickle.dump(model, open('ml_model.pkl', 'wb'))\n",
    "pickle.dump(label_encoder_role, open('role_encoder.pkl', 'wb'))\n",
    "pickle.dump(tfidf, open('tfidf_vectorizer.pkl', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
